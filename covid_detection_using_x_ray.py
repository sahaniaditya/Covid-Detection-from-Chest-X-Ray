# -*- coding: utf-8 -*-
"""Covid Detection Using X-Ray.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LWDPv8UWCeCEcH-9LFtXzwVO5HkJrEe6
"""

from google.colab import drive
drive.mount('/content/drive')
import os
os.chdir('/content/drive/My Drive/X-ray')

import shutil


source_directory = '/content/drive/My Drive/X-ray'

# https://drive.google.com/drive/folders/1U9AZEc2Bqp7wFYmklkpcpKjcWc5pl213?usp=drive_link

"""## DATA VISUALIZATION"""

import os
import matplotlib.pyplot as plt
from PIL import Image

# Define the path to the directory containing COVID and Non-COVID images
dataset_path = '/content/drive/My Drive/X-ray'

# Define paths to random COVID and Non-COVID images
covid_image_path = os.path.join(dataset_path, 'COVID', os.listdir(os.path.join(dataset_path, 'COVID'))[2])
non_covid_image_path = os.path.join(dataset_path, 'Non-COVID', os.listdir(os.path.join(dataset_path, 'Non-COVID'))[602])

# Load and display the COVID image in black and white
covid_image = Image.open(covid_image_path)
plt.subplot(1, 2, 1)
plt.title("COVID Image")
plt.imshow(covid_image, cmap='gray')
plt.axis('off')

# Load and display the Non-COVID image in color
non_covid_image = Image.open(non_covid_image_path)
plt.subplot(1, 2, 2)
plt.title("Non-COVID Image")
plt.imshow(non_covid_image, cmap='gray')
plt.axis('off')

plt.show()

"""## IMAGE ENHANCEMENT USING HISTOGRAM EQUILIZATION"""

import cv2

# # Load the COVID image
 covid_image = cv2.imread(covid_image_path, cv2.IMREAD_GRAYSCALE)

# # Apply histogram equalization to the COVID image
 covid_image_equalized = cv2.equalizeHist(covid_image)

# # Load the Non-COVID image
 non_covid_image = cv2.imread(non_covid_image_path, cv2.IMREAD_GRAYSCALE)

# # Apply histogram equalization to the Non-COVID image
 non_covid_image_equalized = cv2.equalizeHist(non_covid_image)

# # Display the enhanced images
 plt.figure(figsize=(12, 6))

 plt.subplot(2, 2, 1)
 plt.title("Original COVID Image")
 plt.imshow(covid_image, cmap='gray')
 plt.axis('off')

 plt.subplot(2, 2, 2)
 plt.title("Enhanced COVID Image (Histogram Equalization)")
 plt.imshow(covid_image_equalized, cmap='gray')
 plt.axis('off')

 plt.subplot(2, 2, 3)
 plt.title("Original Non-COVID Image")
 plt.imshow(non_covid_image, cmap='gray')
 plt.axis('off')

 plt.subplot(2, 2, 4)
 plt.title("Enhanced Non-COVID Image (Histogram Equalization)")
 plt.imshow(non_covid_image_equalized, cmap='gray')
 plt.axis('off')

 plt.show()

"""## ENHANCING ALL THE IMAGES AND SAVING THEM IN DIRECTORY(DO NOT RUN THIS CELL)"""

#  import cv2
#  import os
#  from PIL import Image

# # # Define the path to the directory containing COVID and Non-COVID images
#  dataset_path = '/content/drive/MyDrive/X-ray-20231027T074754Z-002/X-ray'

# # # Create directories to store the enhanced images
#  enhanced_covid_dir = os.path.join(dataset_path, 'Enhanced_COVID_Images')
#  os.makedirs(enhanced_covid_dir, exist_ok=True)

#  enhanced_non_covid_dir = os.path.join(dataset_path, 'Enhanced_Non-COVID_Images')
#  os.makedirs(enhanced_non_covid_dir, exist_ok=True)

# # # Function to apply histogram equalization to an image
#  def apply_histogram_equalization(image_path):
#      image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
#      equalized_image = cv2.equalizeHist(image)
#      return equalized_image

# # # Process and save all COVID images
#  covid_dir = os.path.join(dataset_path, 'COVID')
#  for filename in os.listdir(covid_dir):
#      if filename.lower().endswith(('.jpg', '.jpeg', '.png')):  # Process various image formats
#          image_path = os.path.join(covid_dir, filename)
#          enhanced_image = apply_histogram_equalization(image_path)
#          enhanced_pil_image = Image.fromarray(enhanced_image)

# #         # Save the enhanced image with "enhanced_" prefix to the Enhanced_COVID_Images folder
#          enhanced_pil_image.save(os.path.join(enhanced_covid_dir, 'enhanced_' + filename))

# # # Process and save all Non-COVID images
#  non_covid_dir = os.path.join(dataset_path, 'Non-COVID')
#  for filename in os.listdir(non_covid_dir):
#      if filename.lower().endswith(('.jpg', '.jpeg', '.png')):  # Process various image formats
#          image_path = os.path.join(non_covid_dir, filename)
#          enhanced_image = apply_histogram_equalization(image_path)
#          enhanced_pil_image = Image.fromarray(enhanced_image)

# #         # Save the enhanced image with "enhanced_" prefix to the Enhanced_Non-COVID_Images folder
#          enhanced_pil_image.save(os.path.join(enhanced_non_covid_dir, 'enhanced_' + filename))

"""## DATA PREPROCESSING"""

import os
import cv2
import pandas as pd

# Define the path to the directory containing COVID and Non-COVID images
dataset_path = '/content/drive/MyDrive/X-ray'

# Create lists to store file paths and labels
data = []
labels = []

# Process COVID images
covid_dir = os.path.join(dataset_path, 'Enhanced_COVID_Images')
for filename in os.listdir(covid_dir):
    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
        data.append((os.path.join(covid_dir, filename)))
        labels.append('COVID-POSITIVE')

# Process Non-COVID images
non_covid_dir = os.path.join(dataset_path, 'Enhanced_Non-COVID_Images')
for filename in os.listdir(non_covid_dir):
    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
        data.append((os.path.join(non_covid_dir, filename)))
        labels.append('COVID-NEGATIVE')

# Create a DataFrame
data = pd.DataFrame({'Data': data, 'Label': labels})

# Display the DataFrame
print(data.head())
print(labels[1])

labels

data.shape

num_samples_to_check = 10  # Adjust this number as needed

for i in range(num_samples_to_check):
    print(f"Data: {data.iloc[i]['Data']}")
    # print(f"Label: {data.iloc[i]['Label']}")
    print()

from tensorflow.keras.preprocessing.image import ImageDataGenerator
# Define image dimensions
image_height = 150
image_width = 150
num_channels = 2
# Create an ImageDataGenerator with preprocessing and augmentation options
datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    shear_range=0.2,
    zoom_range=0.2,
    fill_mode='nearest'
)

data.shape

import random

# # Choose 3 random image indices
random_indices = random.sample(range(data.shape[0]), 3)
image_directory = '/content/drive/My Drive/X-ray'

# Get the random image paths
print(random_indices)
# random_image_paths = data[random_indices]
random_image_paths = []
for i in random_indices:
  random_image_paths.append(data.iloc[i,:])


# Create a subplot with 1 row and 3 columns
plt.figure(figsize=(15, 5))
for i, random_image_path in enumerate(random_image_paths, 1):
    plt.subplot(1, 3, i)

    # Unpack the path and label
    image_path, label = random_image_path
    print(image_path)

    # Load the image
    image = cv2.imread(os.path.join(image_directory, image_path))

    if image is not None:
        print(f"Image shape for {image_path}: {image.shape}")
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        plt.imshow(image)
        plt.title(f'Label: {label}')
        plt.axis('off')
    else:
        print(f"Error loading image: {image_path}")

plt.show()

data.shape

data.info()

import cv2
import numpy as np
import concurrent.futures
from tqdm import tqdm
import pandas as pd

# Assuming 'data' is a pandas DataFrame with the 'Data' column
# data = pd.DataFrame({'Data': [data]})  # Replace [...] with your data

# Assuming the 'Data' column is in the first column (index 0)
data_column_index = 0

data_column = data["Data"].astype(str)  # Use array indexing here
# print(data_column.info())
# Define the number of channels
num_channels = 2

# Define the target size for resizing
target_size = (150, 150)

# Function to process an image with error handling and logging
def process_image(image_path):
    try:
        # print("PATH : ", image_path)
        img = cv2.imread(image_path)
        # print("CAT : ",img)
        img = cv2.resize(img, target_size)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        return img
    except Exception as e:
        # print(f"Error processing image: {image_path}")
        # print(f"Error message: {str(e)}")
        # print("apple")
        return None

num_workers = 3

# Create an empty array to store the processed images
X = np.empty((len(data), *target_size, num_channels))
with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:
    futures = [executor.submit(process_image, image_path) for image_path in data_column]
    for i, future in enumerate(tqdm(concurrent.futures.as_completed(futures), total=len(data), unit='image', desc='Processing images')):
        img = future.result()
        if img is not None:
            X[i, :, :, 0] = img
            X[i, :, :, 1] = img

# X is now a NumPy array with shape (number_of_images, 150, 150, 2)
# print(X.shape)

X

X = X/255

X.shape



import random

# Number of images to display for each class
num_images_to_display = 5

plt.figure(figsize=(10, 5))

for i, label in enumerate(['COVID-POSITIVE', 'COVID-NEGATIVE']):
    indices = np.where(labels == label)[0]
    random_indices = random.sample(indices.tolist(), num_images_to_display)

    for j, index in enumerate(random_indices, 1):
        plt.subplot(2, num_images_to_display, i * num_images_to_display + j)
        img = X[index, :, :, 0]  # Assuming you are working with grayscale images
        intensity_values = img.ravel()
        plt.hist(intensity_values, bins=50, alpha=0.7, label=f'Image {j}')
        plt.xlabel('Pixel Intensity')
        plt.ylabel('Frequency')
        plt.title(f'{label} - Image {j}')

plt.tight_layout()
plt.show()

import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import skew, kurtosis

# Function to calculate additional pixel intensity features
def calculate_additional_pixel_intensity_features(image):
    flattened_image = image.flatten()
    mean_intensity = np.mean(flattened_image)
    median_intensity = np.median(flattened_image)
    std_dev_intensity = np.std(flattened_image)
    skewness_intensity = skew(flattened_image)
    kurtosis_intensity = kurtosis(flattened_image)
    return mean_intensity, median_intensity, std_dev_intensity, skewness_intensity, kurtosis_intensity

# Lists to store features and labels
additional_pixel_intensity_features = []

# Process and compute additional pixel intensity features for all images
for index in range(len(data)):
    image = X[index, :, :, 0]  # Assuming you are working with grayscale images

    # Ensure the labels array has the correct length
    # if index < len(labels):
    #     labels = labels[index]

    # Calculate additional pixel intensity features
    features = calculate_additional_pixel_intensity_features(image)

    # Append features to the list
    additional_pixel_intensity_features.append(features)

# Convert the lists to NumPy arrays
additional_pixel_intensity_features_array = np.array(additional_pixel_intensity_features)

# Create a DataFrame
df_additional_pixel_intensity = pd.DataFrame(additional_pixel_intensity_features_array, columns=['Mean', 'Median', 'StdDev', 'Skewness', 'Kurtosis'])
df_additional_pixel_intensity['Labels'] = labels[:len(additional_pixel_intensity_features)]

# Display the DataFrame
print(df_additional_pixel_intensity.head())

# Visualize the distribution of features
sns.pairplot(df_additional_pixel_intensity, hue='Labels', diag_kind='kde')
plt.show()

labels

import cv2
import matplotlib.pyplot as plt
import seaborn as sns

# Function to load and preprocess an image
def load_and_preprocess_image(image_path, target_size=(100, 100)):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is not None:
        img = cv2.resize(img, target_size)
    return img

plt.figure(figsize=(12, 6))

for i, label in enumerate(['COVID-POSITIVE', 'COVID-NEGATIVE']):
    plt.subplot(1, 2, i + 1)
    images = data[data["Label"] == label]["Data"]  # Assuming the column indices for 'Data' and 'Label' are 0 and 1
    intensity_values = []

    for image_path in images:
        img = load_and_preprocess_image(image_path)
        if img is not None:
            intensity_values.extend(img.ravel())

    # Plot histogram using Seaborn for better aesthetics
    sns.histplot(intensity_values, bins=50, color='b' if i == 0 else 'r', alpha=0.7, kde=True)

    plt.xlabel('Pixel Intensity')
    plt.ylabel('Frequency')
    plt.title(f'{label} Image Intensity Distribution')

plt.tight_layout()
plt.show()

"""## FEATURE EXTRACTION"""

import os
import cv2
import numpy as np
from skimage.feature import hog
from skimage import exposure

# Function to compute HOG features for an image
def compute_hog_features(image):
    # Compute HOG features
    features, hog_image = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True, multichannel=False)


    hog_image = exposure.rescale_intensity(hog_image, in_range=(0, 10))

    return features, hog_image

# List to store computed HOG features and HOG images
hog_features_list = []
hog_images_list = []

# Process and compute HOG features for all images
for image_path in images:
    # Load the image
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    image = cv2.resize(image, target_size)

    # Compute HOG features and HOG image
    features, hog_image = compute_hog_features(image)

    # Append features and HOG image to the lists
    hog_features_list.append(features)
    hog_images_list.append(hog_image)

# Convert the lists to NumPy arrays
hog_features_array = np.array(hog_features_list)
hog_images_array = np.array(hog_images_list)

# Display a sample HOG image
sample_hog_image = hog_images_array[0]
plt.imshow(sample_hog_image, cmap='gray')
plt.title('Sample HOG Image')
plt.axis('off')
plt.show()

print(len(labels))  # Print the length of the labels list
print(labels)       # Print the entire labels list to examine its content



labels_array = np.array(labels)
print(labels[800])

import matplotlib.pyplot as plt

# Assuming hog_features_array is a 1D array
hog_features = hog_features_array

plt.figure(figsize=(8, 6))
plt.hist(hog_features, bins=20)  # Adjust the number of bins as needed
plt.title('Histogram of HOG Features')
plt.xlabel('Value')
plt.ylabel('Frequency')
plt.grid()
plt.show()

print("hog_features_array shape:", hog_features_array.shape)
print("labels_array shape:", labels_array.shape)

# Check data types
print("hog_features_array dtype:", hog_features_array.dtype)
print("labels_array dtype:", labels_array.dtype)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(hog_features_array, labels_array[:1638], test_size=0.2, random_state=42)

# unique_classes_train = np.unique(y_train)
# print("Unique Classes in Training Data:", unique_classes_train)

# from sklearn.svm import SVC
# from sklearn.metrics import accuracy_score
# # Create an SVM model
# svm_model = SVC(kernel='rbf', random_state=42)

# # Train the SVM model on the training data
# svm_model.fit(X_train, y_train)

# # Make predictions on the test set
# y_pred = svm_model.predict(X_test)

# # Evaluate the model
# accuracy = accuracy_score(y_test, y_pred)
# print(f'SVM Model Accuracy: {accuracy}')

# import numpy as np
# import cv2
# from skimage.feature import hog
# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import StandardScaler
# from sklearn.linear_model import LogisticRegression
# from sklearn.svm import SVC
# from sklearn.neighbors import KNeighborsClassifier
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.naive_bayes import GaussianNB
# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# import numpy as np
# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import StandardScaler
# from sklearn.linear_model import LogisticRegression
# from sklearn.svm import SVC
# from sklearn.neighbors import KNeighborsClassifier
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.naive_bayes import GaussianNB
# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# # Assuming X_train, X_test, y_train, y_test are already defined with shape (samples, height, width, channels)

# # Reshape the data to (samples, height * width * channels)
# X_train_reshaped = X_train.reshape(X_train.shape[0], -1)
# X_test_reshaped = X_test.reshape(X_test.shape[0], -1)

# # Standardize the feature values
# scaler = StandardScaler()
# X_train_scaled = scaler.fit_transform(X_train_reshaped)
# X_test_scaled = scaler.transform(X_test_reshaped)

# # Models
# models = {
#     'Logistic Regression': LogisticRegression(random_state=42),
#     'Support Vector Machine': SVC(kernel='linear', random_state=42),
#     'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),
#     'Decision Tree': DecisionTreeClassifier(random_state=42),
#     'Random Forest': RandomForestClassifier(random_state=42),
#     'Naive Bayes': GaussianNB()
# }

# for name, model in models.items():
#     model.fit(X_train_scaled, y_train)
#     y_pred = model.predict(X_test_scaled)

#     accuracy = accuracy_score(y_test, y_pred)
#     conf_matrix = confusion_matrix(y_test, y_pred)
#     classification_rep = classification_report(y_test, y_pred)

#     print(f'Model: {name}')
#     print(f'Accuracy: {accuracy}')
#     print(f'Confusion Matrix:\n{conf_matrix}')
#     print(f'Classification Report:\n{classification_rep}')
#     print('---------------------')

# from tensorflow.keras.models import save_model
# import joblib

# # Assuming svm_model is the variable containing your trained SVM model
# svm_model = SVC(kernel='linear', random_state=42)  # You have this line in your code

# # ... (your SVM training code)

# # Save the trained SVM model using joblib
# joblib.dump(svm_model, '/content/drive/My Drive/X-ray-20231027T074754Z-002/svm_model1.joblib')

"""HOG IMPLEMENTATION FROM SCRATCH

"""

import numpy as np

import cv2

# def calculate_gradients(image):
#   sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])
#   sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])

#   gradient_x = cv2.filter2D(image, -1, sobel_x)
#   gradient_y = cv2.filter2D(image, -1, sobel_y)

#   return gradient_x, gradient_y

# def calculate_magnitude_and_angle(gradient_x,gradient_y):
#   magnitude = np.sqrt(gradient_x**2 + gradient_y**2)
#   angle=np.arctan2(gradient_y,gradient_x)*(180/np.pi)
#   return magnitude,angle

# def calculate_histogram(magnitude, angle, cells_per_block):
#     # Divide image into cells
#     cell_size = 8
#     cells_in_x = magnitude.shape[1]
#     cells_in_y = magnitude.shape[0]

#     histograms = []

#     for i in range(cells_in_y):
#         for j in range(cells_in_x):
#             cell_magnitude = magnitude[i * cell_size: (i + 1) * cell_size,
#                                         j * cell_size: (j + 1) * cell_size]
#             cell_angle = angle[i * cell_size: (i + 1) * cell_size,
#                                 j * cell_size: (j + 1) * cell_size]

#             # Calculate histogram for each cell
#             hist, _ = np.histogram(cell_angle, bins=9, range=(0, 180),
#                                    weights=cell_magnitude)

#             histograms.append(hist)

#     histograms = np.array(histograms).reshape(cells_in_y, cells_in_x, 9)

#     return histograms

# def block_normalization(histograms):
#     block_size = 2
#     blocks_in_x = histograms.shape[1] - block_size + 1
#     blocks_in_y = histograms.shape[0] - block_size + 1

#     features = []

#     for i in range(blocks_in_y):
#         for j in range(blocks_in_x):
#             block = histograms[i:i + block_size, j:j + block_size, :].flatten()
#             norm_factor = np.sqrt(np.sum(block**2) + 1e-5)
#             features.append(block / norm_factor)

#     return np.array(features).flatten()

# def extract_hog_features(image):
#     # Grayscale conversion
#     gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

#     # Calculate gradients
#     gradient_x, gradient_y = calculate_gradients(gray_image)

#     # Calculate magnitude and angle
#     magnitude, angle = calculate_magnitude_and_angle(gradient_x, gradient_y)

#     # Calculate histograms for cells
#     histograms = calculate_histogram(magnitude, angle, cells_per_block=2)

#     # Block normalization
#     features = block_normalization(histograms)

#     return features

# image_path = '/content/download.jpg'
# image = cv2.imread(image_path)
# hog_features = extract_hog_features(image)
# print(hog_features)

# import matplotlib.pyplot as plt

# len(hog_features)

# plt.bar(range(len(hog_features)), hog_features)
# plt.title('HOG Features')
# plt.show()

"""# USING CNN IMPLEMENTATION

"""

import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout

model = Sequential()

model.add(Conv2D(4, kernel_size=(3,3), padding="valid", activation="relu", input_shape=(256,256,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2), strides=2, padding="valid"))

model.add(Conv2D(8, kernel_size=(3,3), padding="valid", activation="relu"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2), strides=2, padding="valid"))

model.add(Conv2D(16, kernel_size=(3,3), padding="valid", activation="relu"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2), strides=2, padding="valid"))

model.add(Flatten())

model.add(Dense(16, activation="relu"))
model.add(Dropout(0.1))
model.add(Dense(8, activation="relu"))
model.add(Dropout(0.1))
model.add(Dense(4, activation="relu"))
model.add(Dropout(0.1))


model.add(Dense(1, activation="sigmoid"))

model.summary()

train_ds = keras.utils.image_dataset_from_directory(
    directory = '/content/drive/MyDrive/X-ray/train',
    labels='inferred',
    label_mode = 'int',
    batch_size=32,
    image_size=(256,256)
)

Normalize
def process(image,label):
    image = tf.cast(image/255. ,tf.float32)
    return image,label

train_ds = train_ds.map(process)

for image, label in train_ds:
  print(image, "image shape :  ",image.shape,  "Lable :  ", label)

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

# history = model.fit(train_ds,epochs=1, batch_size=32)

import cv2

import matplotlib.pyplot as plt

# test_img = cv2.imread("/content/download.jpg")

# test_img

# print(test_img)

# plt.imshow(test_img)

# test_img = cv2.resize(test_img,(256,256))

# test_input = test_img.reshape((1,256,256,3))

# model.predict(test_input)

## LBP IMPLEMENATATION

import cv2
import numpy as np
from matplotlib import pyplot as plt


def get_pixel(img, center, x, y):

	new_value = 0

	try:
		# If local neighbourhood pixel
		# value is greater than or equal
		# to center pixel values then
		# set it to 1
		if img[x][y] >= center:
			new_value = 1

	except:
		# Exception is required when
		# neighbourhood value of a center
		# pixel value is null i.e. values
		# present at boundaries.
		pass

	return new_value

# Function for calculating LBP
def lbp_calculated_pixel(img, x, y):

	center = img[x][y]

	val_ar = []

	# top_left
	val_ar.append(get_pixel(img, center, x-1, y-1))

	# top
	val_ar.append(get_pixel(img, center, x-1, y))

	# top_right
	val_ar.append(get_pixel(img, center, x-1, y + 1))

	# right
	val_ar.append(get_pixel(img, center, x, y + 1))

	# bottom_right
	val_ar.append(get_pixel(img, center, x + 1, y + 1))

	# bottom
	val_ar.append(get_pixel(img, center, x + 1, y))

	# bottom_left
	val_ar.append(get_pixel(img, center, x + 1, y-1))

	# left
	val_ar.append(get_pixel(img, center, x, y-1))

	# Now, we need to convert binary
	# values to decimal
	power_val = [1, 2, 4, 8, 16, 32, 64, 128]

	val = 0

	for i in range(len(val_ar)):
		val += val_ar[i] * power_val[i]

	return val

path = '/content/download.jpg'
img_bgr = cv2.imread(path, 1)

height, width, _ = img_bgr.shape

# We need to convert RGB image
# into gray one because gray
# image has one channel only.
img_gray = cv2.cvtColor(img_bgr,
						cv2.COLOR_BGR2GRAY)

# Create a numpy array as
# the same height and width
# of RGB image
img_lbp = np.zeros((height, width),
				np.uint8)

for i in range(0, height):
	for j in range(0, width):
		img_lbp[i, j] = lbp_calculated_pixel(img_gray, i, j)

plt.imshow(img_bgr)
plt.show()

plt.imshow(img_lbp, cmap ="gray")
plt.show()

print("LBP Program is finished")

